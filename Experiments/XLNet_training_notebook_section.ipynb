{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOlLKRvWjyPT",
        "outputId": "a780d2d0-9000-4f2a-b230-421c16372b54"
      },
      "outputs": [],
      "source": [
        "# %pip install transformers\n",
        "# %pip install SentencePiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmzqoJEoR_YU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import textwrap\n",
        "import progressbar as pgr\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IucGicGmSIFM",
        "outputId": "956ba131-9460-44aa-ce30-cbe60d3fd5fe"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj7R7JtLSNWK"
      },
      "outputs": [],
      "source": [
        "train_set = pd.read_csv(\"/content/drive/My Drive/BTP/train.csv\")\n",
        "test_set = pd.read_csv(\"/content/drive/My Drive/BTP/test.csv\")\n",
        "validation_set = pd.read_csv(\"/content/drive/My Drive/BTP/dev.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yrpngo4Ap4bV",
        "outputId": "a1ffe5c4-4f90-4bc0-a863-0de4cd6be6b1"
      },
      "outputs": [],
      "source": [
        "train_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch3hGExazabm"
      },
      "outputs": [],
      "source": [
        "train_set['text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1x8-TlWHqKo",
        "outputId": "ca5efbb7-bc58-4410-823b-3e43fdd8c82f"
      },
      "outputs": [],
      "source": [
        "print(train_set.shape)\n",
        "print(test_set.shape)\n",
        "print(validation_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hue18_vCJplX",
        "outputId": "d7c89a4b-25d7-4ddd-cbdc-ee6cce3e1aff"
      },
      "outputs": [],
      "source": [
        "import ast \n",
        "\n",
        "for i in range(42835):\n",
        "  train_set['labels'][i]=ast.literal_eval(train_set['labels'][i])\n",
        "\n",
        "for i in range(13039):\n",
        "  test_set['labels'][i]=ast.literal_eval(test_set['labels'][i])\n",
        "\n",
        "for i in range(10200):\n",
        "  validation_set['labels'][i]=ast.literal_eval(validation_set['labels'][i])\n",
        "\n",
        "type(train_set['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXSQ01s-KoN4"
      },
      "outputs": [],
      "source": [
        "type(train_set['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4M0Bah7WY9w"
      },
      "outputs": [],
      "source": [
        "validation_set['text'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsLontsGLyM6"
      },
      "outputs": [],
      "source": [
        "train_set['labels'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3lrXqTHkViN"
      },
      "outputs": [],
      "source": [
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "9446ad47070647449fbd483502fb9474",
            "6ea3323fbc0646ad8082ee10d0240b5a",
            "fe290d5d62c94db0b0187852663887c8",
            "2cb2601130da4ddf9ef43fbde603661f",
            "a412c78feca54004a6f0c9a8f6ef7614",
            "3d0f1d2ff11843c290743c4a4d680f07",
            "c610974599f94644bc95a3c0ab2786e4",
            "56bb4ff42fcc4c7a9e9b41a1d8944fc9",
            "4c1ddc0aadbc499286ccd01a5497862b",
            "9a4cd4d859f448fc902dfbcdb836fd0c",
            "9d1ae2fab4a24c6085a696066ded1c11",
            "7bc0f9116ae74355b9b573ece3515d1e",
            "337ff33451184ffe887f85c7ce0d423a",
            "0008fc659afd4fc9aa4bd9549369434b",
            "7a3f1d7c1f73489a9f431b5a7116d9b1",
            "6cf185c030bb4316b79cf27f6bb2ee64",
            "72e9dc2babfd48a081b06e3fa4095424",
            "d0dfe4e867b24727828adc74b574bc12",
            "06b829ec913f447a94f40e93721954fc",
            "630c04ea35b54a7390c4be0e25259df2",
            "d2e51a71f1554ce78997439e1311566e",
            "85a9df1d9b1342d59176d9f5db70b46b"
          ]
        },
        "id": "gNBsFCTSkcMo",
        "outputId": "b49ab315-88be-4ca2-fe21-f3f71ebf97aa"
      },
      "outputs": [],
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)}\n",
        "\n",
        "model_type = 'xlnet'\n",
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n",
        "model_name = 'xlnet-base-cased'\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGq4hym6WY92"
      },
      "outputs": [],
      "source": [
        "len(train_set['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBf5lLMhWY94"
      },
      "outputs": [],
      "source": [
        "print(train_set['labels'])\n",
        "print(train_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k18mPlRJleTy"
      },
      "outputs": [],
      "source": [
        "# def input_id_maker(dataf, tokenizer):\n",
        "#   input_ids = []\n",
        "#   lengths = []\n",
        "#   pgr.widgets = [pgr.Percentage(), ' ', pgr.Bar(), ' ', pgr.ETA()]\n",
        "#   progress = pgr.ProgressBar(widgets=pgr.widgets, max_value=len(dataf['text']))\n",
        "\n",
        "#   for i in progress(range(len(dataf['text']))):\n",
        "#     sen = dataf['text'].iloc[i]\n",
        "#     sen = tokenizer.tokenize(sen)\n",
        "#     CLS = tokenizer.cls_token\n",
        "#     SEP = tokenizer.sep_token\n",
        "#     if(len(sen) > 510):\n",
        "#       sen = sen[len(sen)-510:]\n",
        "\n",
        "#     sen = sen + [SEP] + [CLS]\n",
        "#     encoded_sent = tokenizer.convert_tokens_to_ids(sen)\n",
        "#     input_ids.append(encoded_sent)\n",
        "#     lengths.append(len(encoded_sent))\n",
        "\n",
        "#   input_ids = pad_sequences(input_ids, maxlen=512, value=0, dtype=\"long\", truncating=\"pre\", padding=\"pre\")\n",
        "#   return input_ids, lengths\n",
        "\n",
        "def input_id_maker(dataf, tokenizer):\n",
        "  input_ids = []\n",
        "  lengths = []\n",
        "  temp=[0]\n",
        "  pgr.widgets = [pgr.Percentage(), ' ', pgr.Bar(), ' ', pgr.ETA()]\n",
        "  progress = pgr.ProgressBar(widgets=pgr.widgets, max_value=len(dataf['text']))\n",
        "## missed the last 512 words extraction\n",
        "  for i in progress(range(len(dataf['text']))):\n",
        "    input_id_temp=[]\n",
        "    sen = dataf['text'].iloc[i]\n",
        "    sen = tokenizer.tokenize(sen)\n",
        "    CLS = tokenizer.cls_token\n",
        "    SEP = tokenizer.sep_token\n",
        "    r_col=0\n",
        "    l=len(sen)\n",
        "    rg=0\n",
        "    while(l > 510):\n",
        "      t = sen[rg:rg+510] + [SEP]+ [CLS]\n",
        "      encoded_sent = tokenizer.convert_tokens_to_ids(t)\n",
        "      #temp[0]=encoded_sent\n",
        "      input_id_temp.append(encoded_sent)\n",
        "      l=l-510\n",
        "      rg=rg+510\n",
        "      r_col+=1\n",
        "    if(l!=0):\n",
        "      t=sen[rg: ]+ [SEP]+ [CLS]\n",
        "      encoded_sent=[]\n",
        "      encoded_sent.append(tokenizer.convert_tokens_to_ids(t))\n",
        "      # encoded_sent=encoded_sent.reshape(1,encoded_sent.shape[0])\n",
        "      encoded_sent = pad_sequences(encoded_sent, maxlen=512, value=0, dtype=\"long\", truncating=\"pre\", padding=\"pre\")\n",
        "      encoded_sent=encoded_sent.tolist()\n",
        "      input_id_temp.append(encoded_sent[0])\n",
        "      r_col+=1 #r_col contains count of chunks per record\n",
        "    lengths.append(r_col)\n",
        "    input_ids.append(input_id_temp)\n",
        "  return input_ids, lengths\n",
        "\n",
        "# First dataset is embeded using xlnet pretrained model. Later   these embedding dataset is used to finetune the xlnet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGNYEVMplgDE",
        "outputId": "456673b7-4e9e-4eb2-e047-73892bf254ea"
      },
      "outputs": [],
      "source": [
        "train_input_ids, train_lengths = input_id_maker(train_set, tokenizer)\n",
        "validation_input_ids, validation_lengths = input_id_maker(validation_set, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZz1R9MU90PW",
        "outputId": "217c3090-f798-4860-ab7b-296215757667"
      },
      "outputs": [],
      "source": [
        "test_input_ids, test_lengths = input_id_maker(test_set, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOlEkCyWUlXO",
        "outputId": "56e2c75b-6370-4368-8b25-d3b77952f1a9"
      },
      "outputs": [],
      "source": [
        "test_lengths[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrzGlxr_JsX0"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "dir_path = '/content/drive/My Drive/BTP'\n",
        "\n",
        "# Create an empty pickle file\n",
        "file_path = dir_path + '/train_input.pkl'\n",
        "with open(file_path, 'wb') as f:\n",
        "    pass\n",
        "file_path1 = dir_path + '/validation_input.pkl'\n",
        "with open(file_path, 'wb') as f:\n",
        "    pass\n",
        "# Write your pickled object to the file\n",
        "with open(file_path, 'wb') as f:\n",
        "    pickle.dump(train_input_ids, f)\n",
        "\n",
        "with open(file_path1, 'wb') as f:\n",
        "    pickle.dump(validation_input_ids, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzKKJOOyU7U9"
      },
      "outputs": [],
      "source": [
        "length_path1 = dir_path + '/train_length.pkl'\n",
        "length_path2 = dir_path + '/validation_length.pkl'\n",
        "\n",
        "with open(length_path1, 'wb') as f:\n",
        "    pickle.dump(train_lengths, f)\n",
        "\n",
        "with open(length_path2, 'wb') as f:\n",
        "    pickle.dump(validation_lengths, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsFv3yjUVWjr",
        "outputId": "d069efc2-1257-4178-975c-22bb6868550d"
      },
      "outputs": [],
      "source": [
        "#execute\n",
        "import pickle\n",
        "len_path1= '/content/drive/My Drive/BTP/train_length.pkl'\n",
        "with open(len_path1, 'rb') as f:\n",
        "    # Use pickle.load to deserialize the object from the file\n",
        "    train_lengths = pickle.load(f)\n",
        "len_path2= '/content/drive/My Drive/BTP/validation_length.pkl'\n",
        "with open(len_path2, 'rb') as f:\n",
        "    # Use pickle.load to deserialize the object from the file\n",
        "    validation_lengths = pickle.load(f)\n",
        "\n",
        "max(train_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb5QSmGRM1qn",
        "outputId": "fe628940-f369-430d-912e-1eee0a86cbad"
      },
      "outputs": [],
      "source": [
        "#execute\n",
        "import pickle\n",
        "filepath1= '/content/drive/My Drive/BTP/train_input.pkl'\n",
        "with open(filepath1, 'rb') as f:\n",
        "    # Use pickle.load to deserialize the object from the file\n",
        "    train_input_ids = pickle.load(f)\n",
        "filepath2= '/content/drive/My Drive/BTP/validation_input.pkl'\n",
        "with open(filepath2, 'rb') as f:\n",
        "    # Use pickle.load to deserialize the object from the file\n",
        "    validation_input_ids = pickle.load(f)\n",
        "\n",
        "len(train_input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG-itI05YTGY",
        "outputId": "f05c2e53-a87e-45ad-f94b-3ba559089cdc"
      },
      "outputs": [],
      "source": [
        "print(len(train_input_ids[0][1]))\n",
        "print(train_input_ids[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z1RwJJ5W8oN",
        "outputId": "70d221e3-5c55-4c80-8cae-c23be1e3104e"
      },
      "outputs": [],
      "source": [
        "print(validation_input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRhmL9Oalfhc"
      },
      "outputs": [],
      "source": [
        "# def att_masking(input_ids):\n",
        "#   attention_masks = []\n",
        "#   for sent in input_ids:\n",
        "#     att_mask = [int(token_id > 0) for token_id in sent]\n",
        "#     attention_masks.append(att_mask)\n",
        "#   return attention_masks\n",
        "# changed as per my model\n",
        "def att_masking(input_ids):\n",
        "  attention_masks = [] # it is also 1D array like input_ids[] having each element as list.\n",
        "  for i in range(len(input_ids)):\n",
        "    temp=[]\n",
        "    for sent in input_ids[i]:     #here input_ids[i] contains list of embeded 512 tokens of record i. and sent points to each list in that.\n",
        "      att_mask = [int(token_id > 0) for token_id in sent]\n",
        "      temp.append(att_mask)\n",
        "    attention_masks.append(temp)\n",
        "  return attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_gAls_fSraF"
      },
      "outputs": [],
      "source": [
        "train_attention_masks = att_masking(train_input_ids)\n",
        "validation_attention_masks = att_masking(validation_input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYulou6-B8E0"
      },
      "outputs": [],
      "source": [
        "test_attention_masks = att_masking(test_input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE1i-eektlQW",
        "outputId": "8b05084a-0c14-4999-a3a8-10bda8259efd"
      },
      "outputs": [],
      "source": [
        "test_attention_masks[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKjA4iyaVUJ9",
        "outputId": "fd59cb03-65be-49c5-ef06-e4771b16c4e9"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "unique_sections_train = sorted(set(section for row in train_set['labels'] for section in row))\n",
        "mlb_train = MultiLabelBinarizer(classes=unique_sections_train)\n",
        "y_train0 = mlb_train.fit_transform(train_set['labels'])\n",
        "# for i in range(train.shape[0]):\n",
        "#     y_train0.append(train.loc[i,'labels'])  \n",
        "    \n",
        "unique_sections_dev = sorted(set(section for row in validation_set['labels'] for section in row))\n",
        "mlb_dev = MultiLabelBinarizer(classes=unique_sections_dev)\n",
        "y_dev0 = mlb_dev.fit_transform(validation_set['labels'])\n",
        "# for i in range(dev.shape[0]):\n",
        "#     y_dev0.append(dev.loc[i,'labels'])\n",
        "\n",
        "unique_sections_test = sorted(set(section for row in test_set['labels'] for section in row))\n",
        "mlb_test = MultiLabelBinarizer(classes=unique_sections_test)\n",
        "y_test0 = mlb_test.fit_transform(test_set['labels'])\n",
        "# for i in range(test.shape[0]):\n",
        "#     y_test0.append(test.loc[i,'labels'])\n",
        "\n",
        "print(mlb_train.classes_)\n",
        "print(mlb_dev.classes_)\n",
        "print(mlb_test.classes_)\n",
        "\n",
        "train_labels = y_train0.astype('int')\n",
        "validation_labels = y_dev0.astype('int')\n",
        "test_labels = y_test0.astype('int')\n",
        "\n",
        "y_train0[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1T1LP9TiI16"
      },
      "outputs": [],
      "source": [
        "len(train_labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ-vGwuv84H6",
        "outputId": "f749c35d-ebc2-42f2-a9f9-91408d9aebef"
      },
      "outputs": [],
      "source": [
        "temp1=[]\n",
        "for i in range(len(train_input_ids)):\n",
        "  temp1.append(len(train_input_ids[i]))\n",
        "\n",
        "max(temp1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1Km9m4MIK8X"
      },
      "outputs": [],
      "source": [
        "train_input_ids_arr = np.asarray(train_input_ids, dtype=object)\n",
        "validation_input_ids_arr = np.asarray(validation_input_ids, dtype=object)\n",
        "test_input_ids_arr = np.asarray(test_input_ids, dtype=object)\n",
        "train_attention_masks_arr = np.asarray(train_attention_masks, dtype=object)\n",
        "validation_attention_masks_arr = np.asarray(validation_attention_masks, dtype=object)\n",
        "test_attention_masks_arr = np.asarray(test_attention_masks, dtype=object)\n",
        "train_labels_arr = np.asarray(train_labels, dtype=object)\n",
        "validation_labels_arr = np.asarray(validation_labels, dtype=object)\n",
        "test_labels_arr = np.asarray(test_labels, dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OX2u7GjhTnw"
      },
      "outputs": [],
      "source": [
        "train_input_ids_arr = np.array([np.array(x) for x in train_input_ids_arr)\n",
        "validation_input_ids_arr = np.array([np.array(x) for x in validation_input_ids_arr])\n",
        "test_input_ids_arr = np.array([np.array(x) for x in test_input_ids_arr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuQpfkKCCSBi"
      },
      "outputs": [],
      "source": [
        "train_input_ids_path = \"/content/drive/My Drive/BTP/input_ids/train_input_ids.npy\"\n",
        "validation_input_ids_path = \"/content/drive/My Drive/BTP/input_ids/validation_input_ids.npy\"\n",
        "test_input_ids_path = \"/content/drive/My Drive/BTP/input_ids/test_input_ids.npy\"\n",
        "train_attention_masks_path = \"/content/drive/My Drive/BTP/masks/train_attention_masks.npy\"\n",
        "validation_attention_masks_path = \"/content/drive/My Drive/BTP/masks/validation_attention_masks.npy\"\n",
        "test_attention_masks_path = \"/content/drive/My Drive/BTP/masks/test_attention_masks.npy\"\n",
        "train_labels_path = \"/content/drive/My Drive/BTP/labels/train_labels.npy\"\n",
        "validation_labels_path = \"/content/drive/My Drive/BTP/labels/validation_labels.npy\"\n",
        "test_labels_path = \"/content/drive/My Drive/BTP/labels/test_labels.npy\"\n",
        "\n",
        "np.save(train_input_ids_path, train_input_ids_arr)\n",
        "np.save(validation_input_ids_path, validation_input_ids_arr)\n",
        "np.save(test_input_ids_path, test_input_ids_arr)\n",
        "np.save(train_attention_masks_path, train_attention_masks_arr)\n",
        "np.save(validation_attention_masks_path, validation_attention_masks_arr)\n",
        "np.save(test_attention_masks_path, test_attention_masks_arr)\n",
        "np.save(train_labels_path, train_labels_arr)\n",
        "np.save(validation_labels_path, validation_labels_arr)\n",
        "np.save(test_labels_path, test_labels_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYE6qP9sStLg",
        "outputId": "4f993977-0bcd-4e2e-da69-f198318216dc"
      },
      "outputs": [],
      "source": [
        "# train_inputs = train_input_ids\n",
        "# validation_inputs = validation_input_ids\n",
        "# train_masks = train_attention_masks\n",
        "# validation_masks = validation_attention_mask\n",
        "test = train_input_ids[1000:2000]\n",
        "temp_tensor_list = [torch.tensor(lst) for lst in test]\n",
        "max_len = 346\n",
        "padded_tensors = []\n",
        "for tensor in temp_tensor_list:\n",
        "    # determine length of current tensor\n",
        "    current_len = tensor.size(0)\n",
        "    # if current tensor is shorter than max length, pad with zeros\n",
        "    if current_len < max_len:\n",
        "        pad_size = (max_len - current_len, tensor.size(1))\n",
        "        tensor = torch.cat((tensor, torch.zeros(pad_size)), dim=0)\n",
        "        tensor = tensor.type(torch.int64)\n",
        "    # if current tensor is longer than max length, trim\n",
        "    elif current_len > max_len:\n",
        "        tensor = tensor.narrow(0, 0, max_len)\n",
        "    padded_tensors.append(tensor)\n",
        "\n",
        "# padded_tensors[0:5]\n",
        "# import torch.nn.utils.rnn as rnn_utils\n",
        "test_tensors = torch.stack(padded_tensors)\n",
        "test_tensors.shape\n",
        "# test_tensor1 = rnn_utils.pad_sequence([torch.tensor(lst) for lst in test], batch_first=True)\n",
        "# train_inputs = torch.tensor(train_inputs)\n",
        "# train_labels = torch.tensor(train_labels)\n",
        "# train_masks = torch.stack([torch.stack([torch.tensor(item) for item in sublist]) for sublist in train_masks])\n",
        "# train_masks = torch.tensor(train_masks)\n",
        "# validation_inputs = torch.stack([torch.stack([torch.tensor(item) for item in sublist]) for sublist in validation_inputs])\n",
        "# validation_inputs = torch.tensor(validation_inputs)\n",
        "# validation_labels = torch.tensor(validation_labels)\n",
        "# validation_masks = torch.tensor(validation_masks)\n",
        "# validation_masks = torch.stack([torch.stack([torch.tensor(item) for item in sublist]) for sublist in validation_masks])\n",
        "# # train_inputs = rnn_utils.pad_sequence([torch.tensor(lst) for lst in train_inputs], batch_first=True)\n",
        "# # train_inputs = torch.tensor(train_inputs)\n",
        "# train_labels = torch.tensor(train_labels)\n",
        "# # train_masks = torch.stack([torch.stack([torch.tensor(item) for item in sublist]) for sublist in train_masks])\n",
        "# # train_masks = torch.tensor(train_masks)\n",
        "# # validation_inputs = torch.stack([torch.stack([torch.tensor(item) for item in sublist]) for sublist in validation_inputs])\n",
        "# # validation_inputs = torch.tensor(validation_inputs)\n",
        "# validation_labels = torch.tensor(validation_labels)\n",
        "# # validation_masks = torch.tensor(validation_masks)\n",
        "# # validation_masks = torch.stack([torch.stack([torch.tensor(item) for item in sublist]) for sublist in validation_masks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNyJu_tlkPsU"
      },
      "outputs": [],
      "source": [
        "fold_dir = \"/content/drive/My Drive/BTP/folds\"\n",
        "os.makedirs(fold_dir, exist_ok=True)\n",
        "fold_filename = os.path.join(fold_dir, f\"folds.pt\")\n",
        "\n",
        "with open(fold_filename, \"ab\") as f:\n",
        "    torch.save(test_tensors, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saOqaJfaktkO",
        "outputId": "e906dadd-86e9-4729-c78f-71a7bc8ebb01"
      },
      "outputs": [],
      "source": [
        "test_ten = torch.load(\"/content/drive/My Drive/BTP/folds/folds.pt\")\n",
        "test_ten.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D-cb2s2mViq",
        "outputId": "eb751085-2dfd-4eec-f099-bb3290b664ba"
      },
      "outputs": [],
      "source": [
        "test_ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKALNXZ3K9iH"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import gc\n",
        "\n",
        "fold_dir = \"/content/drive/My Drive/BTP/folds\"\n",
        "os.makedirs(fold_dir, exist_ok=True)\n",
        "\n",
        "max_fold_size = 2000\n",
        "num_folds = math.ceil(len(train_input_ids) / max_fold_size)\n",
        "\n",
        "\n",
        "for fold_num in range(num_folds):\n",
        "    start_idx = fold_num * max_fold_size\n",
        "    end_idx = min(start_idx + max_fold_size, len(train_input_ids))\n",
        "    fold_input_ids = train_input_ids[start_idx:end_idx]\n",
        "    \n",
        "    temp_tensor_list = [torch.tensor(lst) for lst in fold_input_ids]\n",
        "    max_len = 346\n",
        "    for tensor in temp_tensor_list:\n",
        "        padded_tensors = []\n",
        "        # determine length of current tensor\n",
        "        current_len = tensor.size(0)\n",
        "        # if current tensor is shorter than max length, pad with zeros\n",
        "        if current_len < max_len:\n",
        "            pad_size = (max_len - current_len, tensor.size(1))\n",
        "            tensor = torch.cat((tensor, torch.zeros(pad_size)), dim=0)\n",
        "            tensor = tensor.type(torch.int64)\n",
        "        # if current tensor is longer than max length, trim\n",
        "        elif current_len > max_len:\n",
        "            tensor = tensor.narrow(0, 0, max_len)\n",
        "        padded_tensors.append(tensor)\n",
        "\n",
        "    test_tensors = torch.stack(padded_tensors)\n",
        "    fold_filename = os.path.join(fold_dir, f\"fold_{fold_num}.pt\")\n",
        "    torch.save(test_tensors, fold_filename)\n",
        "    \n",
        "    # remove unnecessary data to free up memory\n",
        "    del temp_tensor_list\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFVxg_xa6S1t",
        "outputId": "e11e33bb-7f57-4ce6-895c-889849e67849"
      },
      "outputs": [],
      "source": [
        "padded_tensors[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "_lZnhZTR6yQU",
        "outputId": "bf106dc8-6b69-40e6-9406-e8b7251b1354"
      },
      "outputs": [],
      "source": [
        "train_input_temp = torch.tensor(padded_tensors)\n",
        "train_input_temp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--fOhZBty322",
        "outputId": "06693544-68b4-490d-bbfb-03070aab61ef"
      },
      "outputs": [],
      "source": [
        "test_tensor1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQQ_UpsOz-8I"
      },
      "outputs": [],
      "source": [
        "test2 = train_inputs[5000:10001]\n",
        "test_tensor2 = rnn_utils.pad_sequence([torch.tensor(lst) for lst in test], batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRsozMp8pd8E",
        "outputId": "a5305a4b-995e-4823-d1e6-12ace48d5929"
      },
      "outputs": [],
      "source": [
        "train_inputs_tensor[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OUygsSTSu4W"
      },
      "outputs": [],
      "source": [
        "batch_size = 600\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size = batch_size)\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = RandomSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqCQzHw5Sw6r",
        "outputId": "1773388c-c53a-41ec-b18f-1c657bfd38c1"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = XLNetForSequenceClassification.from_pretrained(model_name, num_labels=len(y_train0[0]))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovDLTpT8SzHy"
      },
      "outputs": [],
      "source": [
        "lr = 2e-6\n",
        "max_grad_norm = 1.0\n",
        "epochs = 3\n",
        "num_total_steps = len(train_dataloader)*epochs\n",
        "num_warmup_steps = 1000\n",
        "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  # 0.1\n",
        "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, num_training_steps = num_total_steps)\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "seed_val = 21\n",
        "\n",
        "\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzUdfiTE-z-s",
        "outputId": "a885100d-c73c-4cbc-9b24-cdfe3da073c1"
      },
      "outputs": [],
      "source": [
        "for step, batch in enumerate(train_dataloader):\n",
        "    print(\"Train Batch Shape:\", batch[0].shape, batch[1].shape, batch[2].shape)\n",
        "\n",
        "for step, batch in enumerate(validation_dataloader):\n",
        "    print(\"Validation Batch Shape:\", batch[0].shape, batch[1].shape, batch[2].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "2iQmRh0uS1S4",
        "outputId": "6899a575-0fdf-4e2f-bab2-98cfc462ed7a"
      },
      "outputs": [],
      "source": [
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}. '.format(step, len(train_dataloader)))\n",
        "\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "          outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
        "    \n",
        "        logits = outputs[0]\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        nb_eval_steps += 1\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UjCuuyeS3iw"
      },
      "outputs": [],
      "source": [
        "output_dir = './XLNet_final/' # path to which the fine tuned model is to be saved\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
        "\n",
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./XLNet_final/ \"/content/Drive/My Drive/shared_by_vijit2/LNLP/XLNet/XLNet_right_model/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Jkyq54S78a"
      },
      "outputs": [],
      "source": [
        "labels = test_set.label.to_numpy().astype(int)\n",
        "\n",
        "input_ids, input_lengths = input_id_maker(test_set, tokenizer)\n",
        "attention_masks = att_masking(input_ids)\n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 6  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q4MIi2wTMWE"
      },
      "outputs": [],
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "\n",
        "# Predict \n",
        "for (step, batch) in enumerate(prediction_dataloader):\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RQr3gyjTQY8"
      },
      "outputs": [],
      "source": [
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
        "labels_flat = true_labels.flatten()\n",
        "\n",
        "flat_accuracy(predictions,true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP_-kya3TTD5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import textwrap\n",
        "import progressbar\n",
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s8i8yxZTVT0"
      },
      "outputs": [],
      "source": [
        "def metrics_calculator(preds, test_labels):\n",
        "    cm = confusion_matrix(test_labels, preds)\n",
        "    TP = []\n",
        "    FP = []\n",
        "    FN = []\n",
        "    for i in range(0,2):\n",
        "        summ = 0\n",
        "        for j in range(0,2):\n",
        "            if(i!=j):\n",
        "                summ=summ+cm[i][j]\n",
        "\n",
        "        FN.append(summ)\n",
        "    for i in range(0,2):\n",
        "        summ = 0\n",
        "        for j in range(0,2):\n",
        "            if(i!=j):\n",
        "                summ=summ+cm[j][i]\n",
        "\n",
        "        FP.append(summ)\n",
        "    for i in range(0,2):\n",
        "        TP.append(cm[i][i])\n",
        "    precision = []\n",
        "    recall = []\n",
        "    for i in range(0,2):\n",
        "        precision.append(TP[i]/(TP[i] + FP[i]))\n",
        "        recall.append(TP[i]/(TP[i] + FN[i]))\n",
        "\n",
        "    macro_precision = sum(precision)/2\n",
        "    macro_recall = sum(recall)/2\n",
        "    micro_precision = sum(TP)/(sum(TP) + sum(FP))\n",
        "    micro_recall = sum(TP)/(sum(TP) + sum(FN))\n",
        "    micro_f1 = (2*micro_precision*micro_recall)/(micro_precision + micro_recall)\n",
        "    macro_f1 = (2*macro_precision*macro_recall)/(macro_precision + macro_recall)\n",
        "    return macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1\n",
        "\n",
        "macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(pred_flat, labels_flat)\n",
        "print(macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-fTbt9STYJL"
      },
      "outputs": [],
      "source": [
        "# Set the batch size.  \n",
        "batch_size = 6  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "prediction_sampler = SequentialSampler(validation_data)\n",
        "prediction_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-warWb3Tf8I"
      },
      "outputs": [],
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "\n",
        "# Predict \n",
        "for (step, batch) in enumerate(prediction_dataloader):\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pBr3lOhTjR_"
      },
      "outputs": [],
      "source": [
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
        "labels_flat = true_labels.flatten()\n",
        "\n",
        "flat_accuracy(predictions,true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSext0rUTlQA"
      },
      "outputs": [],
      "source": [
        "macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(pred_flat, labels_flat)\n",
        "print(macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "aabcb3a409ca81aaefa1e72d7735d3a730ff492583c675101f369e79b9ff82fa"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0008fc659afd4fc9aa4bd9549369434b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06b829ec913f447a94f40e93721954fc",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_630c04ea35b54a7390c4be0e25259df2",
            "value": 760
          }
        },
        "06b829ec913f447a94f40e93721954fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cb2601130da4ddf9ef43fbde603661f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a4cd4d859f448fc902dfbcdb836fd0c",
            "placeholder": "",
            "style": "IPY_MODEL_9d1ae2fab4a24c6085a696066ded1c11",
            "value": " 798k/798k [00:00&lt;00:00, 8.97MB/s]"
          }
        },
        "337ff33451184ffe887f85c7ce0d423a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72e9dc2babfd48a081b06e3fa4095424",
            "placeholder": "",
            "style": "IPY_MODEL_d0dfe4e867b24727828adc74b574bc12",
            "value": "Downloading ()lve/main/config.json: 100%"
          }
        },
        "3d0f1d2ff11843c290743c4a4d680f07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c1ddc0aadbc499286ccd01a5497862b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56bb4ff42fcc4c7a9e9b41a1d8944fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "630c04ea35b54a7390c4be0e25259df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cf185c030bb4316b79cf27f6bb2ee64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ea3323fbc0646ad8082ee10d0240b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d0f1d2ff11843c290743c4a4d680f07",
            "placeholder": "",
            "style": "IPY_MODEL_c610974599f94644bc95a3c0ab2786e4",
            "value": "Downloading ()ve/main/spiece.model: 100%"
          }
        },
        "72e9dc2babfd48a081b06e3fa4095424": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a3f1d7c1f73489a9f431b5a7116d9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2e51a71f1554ce78997439e1311566e",
            "placeholder": "",
            "style": "IPY_MODEL_85a9df1d9b1342d59176d9f5db70b46b",
            "value": " 760/760 [00:00&lt;00:00, 20.6kB/s]"
          }
        },
        "7bc0f9116ae74355b9b573ece3515d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_337ff33451184ffe887f85c7ce0d423a",
              "IPY_MODEL_0008fc659afd4fc9aa4bd9549369434b",
              "IPY_MODEL_7a3f1d7c1f73489a9f431b5a7116d9b1"
            ],
            "layout": "IPY_MODEL_6cf185c030bb4316b79cf27f6bb2ee64"
          }
        },
        "85a9df1d9b1342d59176d9f5db70b46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9446ad47070647449fbd483502fb9474": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ea3323fbc0646ad8082ee10d0240b5a",
              "IPY_MODEL_fe290d5d62c94db0b0187852663887c8",
              "IPY_MODEL_2cb2601130da4ddf9ef43fbde603661f"
            ],
            "layout": "IPY_MODEL_a412c78feca54004a6f0c9a8f6ef7614"
          }
        },
        "9a4cd4d859f448fc902dfbcdb836fd0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d1ae2fab4a24c6085a696066ded1c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a412c78feca54004a6f0c9a8f6ef7614": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c610974599f94644bc95a3c0ab2786e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0dfe4e867b24727828adc74b574bc12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2e51a71f1554ce78997439e1311566e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe290d5d62c94db0b0187852663887c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56bb4ff42fcc4c7a9e9b41a1d8944fc9",
            "max": 798011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c1ddc0aadbc499286ccd01a5497862b",
            "value": 798011
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
